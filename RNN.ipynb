{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = [0;0;0;0;1;1;1;0;1;1;1;0;0;0;0;0;1;1;1;0;1;1;1;0;0;0;0;0;1;1;1;0;1;1;1;0]; %12x1\n",
    "numIn = 1;\n",
    "numHid = 4;\n",
    "numOut = 1;\n",
    "theta1 = ( 1 * sqrt ( 6 / ( numIn + numHid) ) * randn( numIn + numHid + 1, numHid ) );\n",
    "theta2 = ( 1 * sqrt ( 6 / ( numHid + numOut ) ) * randn( numHid + 1, numOut ) );\n",
    "theta1_grad = zeros(numIn + numHid + 1, numHid);\n",
    "theta2_grad = zeros(numHid + 1, numOut);\n",
    "epochs = 60000;\n",
    "alpha = 0.006;\n",
    "epsilon = 0.01;\n",
    "thetaVec = [theta1(:);theta2(:)];\n",
    "minErr = 1e-1;\n",
    "hid_last = zeros(numHid, 1);\n",
    "last_change1 = zeros(numIn + numHid + 1, numHid);\n",
    "last_change2 = zeros(numHid + 1, numOut);\n",
    "m = size(X,1);\n",
    "for i = 1:epochs\n",
    "    %forward propagation\n",
    "    s = randi([1 (m-1)]);\n",
    "    for j = s:(m-1) %for every training element\n",
    "        y = X(j+1,:); %expected output, the next element in the sequence\n",
    "        context = sigmoid(hid_last);\n",
    "        a1 = [X(j,:); context; 1]; %add bias, context units to input layer; 3x1\n",
    "        z2 = theta1' * a1; %2x1\n",
    "        a2 = [sigmoid(z2); 1]; %output hidden layer; 3x1\n",
    "        hid_last = a2(1:end-1,1);\n",
    "        z3 = theta2' * a2; %1x1\n",
    "        a3 = sigmoid(z3);\n",
    "        %calculate delta errors\n",
    "        d3 = (a3 - y);\n",
    "        d2 = (theta2 * d3) .* (a2 .* (1 - a2));\n",
    "        %accumulate gradients\n",
    "        theta1_grad = theta1_grad + (d2(1:numHid, :) * a1')'; \n",
    "        theta2_grad = theta2_grad + (d3 * a2')';\n",
    "        \n",
    "    end\n",
    "    theta1_change = alpha * (1/m)*theta1_grad + epsilon * last_change1;\n",
    "    theta2_change = alpha * (1/m)*theta2_grad + epsilon * last_change2;\n",
    "    theta1 = theta1 - theta1_change;\n",
    "    theta2 = theta2 - theta2_change;\n",
    "    last_change1 = theta1_change;\n",
    "    last_change2 = theta2_change;\n",
    "    %reset gradients\n",
    "    theta1_grad = zeros(numIn + numHid + 1, numHid);\n",
    "    theta2_grad = zeros(numHid + 1, numOut);\n",
    "    %compute cost function\n",
    "    thetaVec_ = [theta1(:);theta2(:)];\n",
    "    err = costFunctionRNN(X, thetaVec_);\n",
    "    if err < minErr\n",
    "        disp('Done!');\n",
    "        disp(sprintf('Min err: %d', err));\n",
    "        format = 'When X is %d, hTheta = %0.5f, expected, %0.5f';\n",
    "        S=sprintf(format, X(1,:), a3, y);\n",
    "        disp(S);\n",
    "        break;\n",
    "    end\n",
    "end\n",
    "runRNN(thetaVec_);\n",
    "disp(sprintf('Error at end: %d', err));\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
