{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Re-submission Note</em>: I originally submitted an RNN post but realized I made some major mistakes (I'm learning as I go). This is essentially a complete re-do. One of the issues was that the RNN was not training properly, and I have not been able to get it to reliably train with my own implementation of gradient descent, so here I will calculate the gradients and hand those off to a scipy optimizer to find the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Assumptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm assuming you already know how to build a simple neural network (e.g. to solve XOR) and train it using backpropagation. I have a previous post covering backpropagation/gradient descent and at the end of that tutorial I build and train a neural network to solve the XOR problem, so I recommend making sure you understand that because I am simply adapting that network into a recurrent architecture here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Summary & Motivations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blog is my journey into learning the fundamentals of machine learning and other quantitative principles and applications and is generally in chronological order of my learning. After I successfully learned how to make feedforward neural networks and train them, I really wanted to learn how to make recurrent neural networks (RNNs). I understood that they were for temporal/sequential data and thus they could learn relationships through time. But I could not for the life of me figure out how to make the jump from a feedforward neural net to an RNN until I watched this youtube video: https://www.youtube.com/watch?v=e2sGq_vI41s (which I highly suggest you watch) by Jeff Heaton. Then I understood that RNNs can be implemented almost exactly like an ordinary feedforward neural network. I will re-explain some of the contents of that video here as I build a simple recurrent (Elman) neural network to solve a temporal version of the XOR problem (my favorite toy problem). I will also show you how to basic time series/sequence prediction with a mini-mini-char-RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Converting to Temporal Data: XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a reminder, here is the truth table for XOR.\n",
    "<table>\n",
    "<tr><td>$x_1$</td><td>$x_2$</td><td>$y$</td></tr>\n",
    "<tr><td>$0$</td><td>$0$</td><td>$0$</td></tr>\n",
    "<tr><td>$0$</td><td>$1$</td><td>$1$</td></tr>\n",
    "<tr><td>$1$</td><td>$0$</td><td>$1$</td></tr>\n",
    "<tr><td>$1$</td><td>$1$</td><td>$0$</td></tr>\n",
    "</table>\n",
    "<p>\n",
    "So normally, in a feedforward neural network, we would feed each training example as a tuple $(x_1, x_2)$ and we would expect an output $h(x)$ that closely matches $y$ if the network has been trained. As review, here's what our ordinary feedforward XOR architecture looks like:\n",
    "\n",
    "<img src=\"images/XORnormal.png\" />\n",
    "\n",
    "In an RNN, we're going to add in the time dimension. But how? Well we simply reformat our training data to be in a time-dependent sequence.</p>\n",
    "<p>Here's our new (temporal) training data:</p>\n",
    "<table style=\"width:150px;\">\n",
    "<tr><td>$x$</td><td>$y$</td><td>$t$</td></tr>\n",
    "<tr><td>$0$</td><td>?</td><td>$0$</td></tr>\n",
    "<tr><td>$0$</td><td>0</td><td>$1$</td></tr>\n",
    "<tr><td>$1$</td><td>1</td><td>$2$</td></tr>\n",
    "<tr><td>$1$</td><td>0</td><td>$3$</td></tr>\n",
    "<tr><td>$0$</td><td>1</td><td>$4$</td></tr>\n",
    "<tr><td>$...x_n$</td><td>$...y_n$</td><td>$...t_n$</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $x ... x_n$ represents our training data and $t ... t_n $ represents our time steps. I arranged a sequence of bits [0 0 1 1 0] such that we can XOR the current bit and the previous bit to get the result. For every-time step our RNN is going to make output the XOR of the previous 2 bits, so notice that after the first bit $y=?$ because there is no previous bit to XOR, so we just ignore what the RNN outputs. But for $x=0, t=1$ we see that $y=0$ because XOR(0,0)=0.  Also notice how $time$ is in discrete, integer, steps. Some algorithms may actually have continous time implementation and that's something I'll likely explore in a future post. Let's take another look at our sequential data written horizontally as numpy code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.matrix('[0;0;1;1;0]')\n",
    "Y = np.matrix('[0;0;1;0;1]') #first bit should be ignored, just arbitrarily putting 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "So what do we do with our sequential XOR data and what does our neural network look like? Well, we're simply going to feed each (one at a time) $x$ value into our neural network and expect one output value at a time. Instead of having 2 input units (excluding bias), we only need one now:\n",
    "<img src=\"images/XORrnn.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>What's that loop and $t-1$ thing? Well it means we're going to take our output from the hidden layer at time $t_n$ and feed it back into our hidden layer as additional input at $t_{n+1}$ (the next time step), or we could rephrase that to say that our hidden layer input at $t_n$ includes the output of the hidden layer from $t_{n-1}$ (the previous time step).\n",
    "</p>\n",
    "<p>\n",
    "You might be wondering how this is any more useful than an ordinary feedforward NN, and the answer is it's not really. For a problem like XOR, I can't think of a reason why you'd ever want to use an RNN over a feedforward. We're just using it here because it's familiar and I'm a reductionist.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Elman Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>An Elman network is in the class of \"simple recurrent neural networks\" (presumably because they really are simple, with no frills) and it's the type of RNN we're going to build to solve our temporal XOR problem. Here's what it looks like when applied to our XOR problem:</p>\n",
    "<img src=\"images/XORrnnFull.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>where $\\theta_1$ refers to the weights between the input layer and the hidden layer (a 6x4 matrix) and $\\theta_2$ refers to our weights in between the hidden layer and our output layer (a 5x1 matrix).</p>\n",
    "<p>\n",
    "Okay so everything should make sense here except those 4 units labeled $C_1 - C_4$. Those are called <em>context</em> units in the parlance of simple RNNs. These context units are additional input units that feed the output from $t_{n-1}$'s hidden layer back into $t_n$'s hidden layer. They're treated exactly like a normal input unit, with adjustable weights. (At $t = 0$ there is no history to remember, so we have to initialize our network's context units with something, generally 0s.) Notice that we have the <b>same number of context units as we do hidden units</b>, that's by design and is simply the architecture of an Elman network.\n",
    "</p>\n",
    "<p>\n",
    "So what we've done here by adding context units that feed the previous time step's state into the current time step is to turn that diagram with the t-1 loop into essentially an ordinary feedforward neural network. And since it's a feedforward neural network, we can train it exactly like we do with a feed forward XOR neural network: backpropagation (it often get's called <em>backpropagation through time</em> but it's just a different name for the same thing).</p>\n",
    "<p>\n",
    "Let's walk through the flow of how this works in the feedforward direction for 2 time steps.\n",
    "<ul>\n",
    "<li>1. $t=0$. Start with $x_1 = 0$ (first element in our list), intialize $C_1 - C_4$ to input 0s.</li>\n",
    "<li>2. Feed those inputs (from bottom to top, $x_1, c_4, c_3, c_2, c_1, B_1$): [0,0,0,0,0,1] into the hidden layer (of course we multiply by $\\theta_1$).</li>\n",
    "<li>3. The hidden layer outputs $a_4, a_3, a_2, a_1, B_2$. We'll then store these values (except bias, $B_2$) in another temporary vector for the next time step. </li>\n",
    "<li>4. Then our output unit uses the hidden layer outputs to produce the final output, $g(x)$</li>\n",
    "<li>5. $t=1$ (next time step). So still $x_1 = 0$ (second element in our list), intialize $C_1 - C_4$ to the stored outputs of $H_1 - H_4$ from the last time we ran the network forward.</li>\n",
    "<li>6. Feed those inputs (from bottom to top, $x_1, c_4, c_3, c_2, c_1, B_1$): [0, $H_4^{t-1}, H_3^{t-1}, H_2^{t-1}, H_1^{t-1}$, 1] into the hidden layer.</li>\n",
    "<li>7. The hidden layer outputs $a_4, a_3, a_2, a_1, B_2$. We'll then store these values in the temporary vector for the next time step.</li>\n",
    "<li>8. Then our output unit uses the hidden layer outputs to produce the final output, $g(x)$</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p>\n",
    "<b>Important Notes:</b> As mentioned before, we treat the context units just like ordinary input units, that means they have weighted connections between them and the hidden layer, but their input does not go through any activation function nor do we manipulate those values in anyway before we feed them back in the next time step.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Let's build it (updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So as mentioned before, when I originally posted this article I attemped to train it using ordinary backpropagation/gradient descent (with momentum), and it was not reliably working. So rather than posting some code that may or may not work for you, I'm going to use scipy's optimize functions to help out the training (and even then it has issues converging sometimes). RNNs are infamously difficult to train compared to NNs. (We'll graph is the 3d surface of its cost function to see why later.) </p>\n",
    "\n",
    "<p>\n",
    "If you have taken Andrew Ng's machine learning course, then you should be familiar with Matlab's 'fminunc' optimizer. We're going to use scipy's version, `fmin_tnc`. Let me just walk through the major points of the following implementation\n",
    "<ul>\n",
    "<li>I have a cost function defined in a separate file which accepts an 'unrolled' theta vector, so in the cost function we have to assign theta1 and theta2 by slicing the long thetaVec. This cost function returns the cost ('J') and the gradient (an unrolled vector containing theta1_grad and theta2_grad).</li>\n",
    "<li> In the main code to follow, we give scipy's `fmin_tnc` our cost function and some initial weights and it quickly finds an optimal set of weights. `fmin_tnc` will return the optimal weights as an unrolled vector.</li>\n",
    "<li>After we define theta1 and theta2 from the optimal weights returned, we run the network forward on a different sequence of bits to see if it really learned how to XOR the sequence one step at a time.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sigmoid import sigmoid\n",
    "from scipy import optimize\n",
    "from xorRNN import cost_xorRNN as cr #I defined the cost function in a separate file\n",
    "X = np.matrix('[0;0;1;1;0]') #training data\n",
    "Y = np.matrix('[0;0;1;0;1]') #expect y values for every pair in the sequence of X\n",
    "numIn, numHid, numOut = 1, 4, 1\n",
    "#initial, randomized weights:\n",
    "theta1 = np.matrix( 1 * np.sqrt ( 6 / ( numIn + numHid) ) * np.random.randn( numIn + numHid + 1, numHid ) )\n",
    "theta2 = np.matrix( 1 * np.sqrt ( 6 / ( numHid + numOut ) ) * np.random.randn( numHid + 1, numOut ) )\n",
    "#we're going to concatenate or 'unroll' theta1 and theta2 into a 1-dimensional, long vector\n",
    "thetaVec = np.concatenate((theta1.flatten(), theta2.flatten()), axis=1)\n",
    "#give the optimizer our cost function and our unrolled weight vector\n",
    "opt = optimize.fmin_tnc(cr.costRNN, thetaVec, args=(X, Y), maxfun=2000)\n",
    "#retrieve the optimal weights\n",
    "optTheta = np.array(opt[0])\n",
    "#reconstitute our original 2 weight vectors\n",
    "theta1 = optTheta[0:24].reshape(6, 4)\n",
    "theta2 = optTheta[24:].reshape(5, 1)\n",
    "\n",
    "def runForward(X, theta1, theta2):\n",
    "\tm = X.shape[0]\n",
    "\t#forward propagation\n",
    "\thid_last = np.zeros((numHid, 1)) #context units\n",
    "\tresults = np.zeros((m, 1)) #to save the output\n",
    "\tfor j in range(m):#for every input element\n",
    "\t\tcontext = hid_last\n",
    "\t\tx_context = np.concatenate((X[j,:], context))\n",
    "\t\ta1 = np.matrix(np.concatenate((x_context, np.matrix('[1]'))))#add bias, context units to input layer\n",
    "\t\tz2 = theta1.T * a1 #2x1\n",
    "\t\ta2 = np.concatenate((sigmoid(z2), np.matrix('[1]'))) #add bias, output hidden layer\n",
    "\t\thid_last = a2[0:-1, 0]\n",
    "\t\tz3 = theta2.T * a2 #1x1\n",
    "\t\ta3 = sigmoid(z3)\n",
    "\t\tresults[j] = a3\n",
    "\treturn results\n",
    "\n",
    "Xt = np.matrix('[1;0;0;1;1;0]') #test it out on some new data\n",
    "print(np.round(runForward(Xt, theta1, theta2).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Cool! It worked. Remember, ignore the first bit of the output, it can't XOR just 1 digit. The rest of the sequence [1 0 1 0 1] matches with XOR of each pair of bits along the sequence. You might have to run this code a couple of times before it works because even when using a fancy optimizer, this thing is hard to train.\n",
    "</p>\n",
    "<p>\n",
    "Also note I imported \"sigmoid\" which is a separate file that only contains the sigmoid function and 'cost_xorRNN' which is the cost function.. I'll reproduce both below so you can run everything on your own.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sigmoid.py\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "\treturn np.matrix(1.0 / (1.0 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sigmoid import sigmoid\n",
    "def costRNN(thetaVec, *args):\n",
    "\tX = args[0]\n",
    "\tY = args[1]\n",
    "\tnumIn, numHid, numOut = 1, 4, 1\n",
    "    #reconstitute our theta1 and theta2 from the unrolled thetaVec\n",
    "\ttheta1 = thetaVec[0:24].reshape(6,4)\n",
    "\ttheta2 = thetaVec[24:].reshape(5,1)\n",
    "    #initialize our gradient vectors\n",
    "\ttheta1_grad = np.zeros((numIn + numHid + 1, numHid))\n",
    "\ttheta2_grad = np.zeros((numHid + 1, numOut))\n",
    "    #this will keep track of the output from the hidden layer\n",
    "\thid_last = np.zeros((numHid, 1))\n",
    "\tm = X.shape[0]\n",
    "\tJ = 0 #cost output\n",
    "\tresults = np.zeros((m, 1)) #to store the output of the network\n",
    "    #this is to find the gradients:\n",
    "\tfor j in range(m): #for every training element\n",
    "\t\t#y = X[j+1,:] #expected output, the next element in the sequence\n",
    "\t\ty = Y[j]\n",
    "\t\tcontext = hid_last\n",
    "\t\tx_context = np.concatenate((X[j], context)) #add the context units to our input layer\n",
    "\t\ta1 = np.matrix(np.concatenate((x_context, np.matrix('[1]'))))#add bias, context units to input layer; 3x1\n",
    "\t\tz2 = theta1.T * a1; #2x1\n",
    "\t\ta2 = np.concatenate((sigmoid(z2), np.matrix('[1]'))) #add bias, output hidden layer; 3x1\n",
    "\t\thid_last = a2[0:-1, 0];\n",
    "\t\tz3 = theta2.T * a2 #1x1\n",
    "\t\ta3 = sigmoid(z3)\n",
    "\t\tresults[j] = a3\n",
    "\t\t#Backpropagation:::\n",
    "\t\t#calculate delta errors\n",
    "\t\td3 = (a3 - y)\n",
    "\t\td2 = np.multiply((theta2 * d3), np.multiply(a2, (1 - a2)))\n",
    "\t\t#accumulate gradients\n",
    "\t\ttheta1_grad = theta1_grad + (d2[0:numHid, :] * a1.T).T\n",
    "\t\ttheta2_grad = theta2_grad + (d3 * a2.T).T\n",
    "    #calculate the network cost\n",
    "\tfor n in range(m):\n",
    "\t\ta3n = results[n].T\n",
    "\t\tyn = Y[n].T\n",
    "\t\tJ = J + (-yn.T * np.log(a3n) - (1-yn).T * np.log(1-a3n)) #cross-entropy cost function\n",
    "\tJ = (1/m) * J\n",
    "\tgrad = np.concatenate((theta1_grad.flatten(), theta2_grad.flatten()), axis=1) #unroll our gradients\n",
    "\treturn J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Everything should look fairly familiar if you've gone through my post on gradient descent and backpropagation, or already have a decent handle on building an XOR-capable feedforward network, but let me walk through the important/new parts of the code.\n",
    "</p>\n",
    "<p>1. Every training iteration, we temporarily save the hidden layer outputs in `hid_last` and then at the start of the next training iteration, we initialize our context units to what we stored in `hid_last`.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "context = hid_last\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "2. We have 4 context units, we add/concatenate them with our 1 input unit $X_1$ (and the bias of course), so our total input layer contains 6 units. This means our `theta1` is a 6x4 matrix (6 inputs projecting to 4 hidden units). Our hidden layer has 4 hidden units + 1 bias, so `theta2` is a 5x1 matrix. Other than these manipulations, the network is virtually identical to an ordinary feedforward network.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "3. In case the 'unrolling' of matrices is unclear... When we unroll theta1 and theta2 into a single vector, `thetaVec`, we simply flatten those vectors into a 1 dimensional sequence and concatenate them. So `theta1` is a 6x4 matrix (24 total elements) which we flatten to a 24 element vector, and we likewise flatten `theta` (5x1 = 5 elements) to a 5 element vector, then concatenate them in order to produce a 29 element vector, `thetaVec`. Thus the first 24 elements of this vector are `theta1` and the last 5 arre `theta2`, so we can rebuild our original vectors by slicing up `thetaVec` and using `.reshape()` to give us matrices of the proper dimensions.\n",
    "<br /><br />\n",
    "4. Let's discuss the scipy optimizer.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "opt = optimize.fmin_tnc(cr.costRNN, thetaVec, args=(X, Y), maxfun=2000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Scipy's optimizer `fmin_tnc` just wants the reference to our cost function (i.e we're passing the object itself, not calling the function, hence we don't do `cr.costRNN(...)`. But if we do that, how do we pass in the arguments it expects? Well `fmin_tnc` will assume that the first argument our cost function is supposed to be the unrolled theta vector and thus the 2nd argument to `fmin_tnc` is `thetaVec` which we randomly initialize. The optmizer will iteratively modify and improve the theta vec we originally pass in.</p><p>But wait, our cost function also expects `X` and `Y` parameters! We defined the second argument in our cost function to be `*args` which essentially allows us to accept a tuple of arguments there, and that's what `fmin_tnc` is going to do. We give `fmin_tnc` an `args=()` parameter which is a tuple of additional arguments to pass into our cost function. In our case, we just want to pass in our X and Y vectors.\n",
    "</p><p>\n",
    "The 4th parameter we give to `fmin_tnc` is `maxfun=2000` which refers to the maximum number of times the optimizer is allowed to call our cost function. It isn't necessary to set this, but I decided to set it to be higher than default to allow it to hopefully find a better optimum.\n",
    "</p>\n",
    "<p>\n",
    "What does `fmin_tnc` return to us? It returns 3 items by default in an array. The first is the only thing we really care about, our optimal weights stored in an unrolled vector. Hence I retrieve it with this line: `optTheta = np.array(opt[0])`  The other 2 return values are the number of times it called our cost function, and a return code string. You can see the documentation here: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.fmin_tnc.html\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Why is it so difficult to train this thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'cost_xorRNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-99d00434aeca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_xorRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheta_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthetaVec_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetaVec_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-99d00434aeca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_xorRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheta_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthetaVec_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetaVec_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'cost_xorRNN'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1074b5f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from xorRNN import cost_xorRNN as cr\n",
    "%matplotlib inline\n",
    "thetaVec_f = np.random.permutation(np.linspace(-100, 100, 200))\n",
    "thetaVec_all = np.array([ -18.37619967,  124.9886293 ,    0.69066491,   -2.38403005,\n",
    "         -2.3863598 ,   34.07749817,   -4.0086386 ,  -99.19477153,\n",
    "          5.28132817,  154.89424477,   17.32554579,  -64.2570698 ,\n",
    "         16.34582581,  -20.79296525,  -21.30831168,  -15.76185224,\n",
    "          4.64747081,  -65.70656672,   13.59414862,  -53.70279419,\n",
    "        113.13004224,  -33.56398667,    0.7257491 ,   -9.27982256,\n",
    "        -18.29977063,  129.48720956,  -37.57674034,  -30.04523486,\n",
    "        -90.35656788])\n",
    "thetaVec_sample = [np.concatenate((np.array([theta_]), thetaVec_all[1:]), axis=0) for theta_ in np.nditer(thetaVec_f)]\n",
    "Xs = np.matrix('[0;0;1;1;0]')\n",
    "Ys = np.matrix('[0;0;1;0;1]')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "zs = [cr.cost_xorRNN(np.array(theta_s).T, (Xs, Ys)) for theta_s in thetaVec_sample]\n",
    "ax.plot(thetaVec_sample, zs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.10526316,  10.26315789,  -0.78947368,  -3.94736842,\n",
       "        -8.68421053,  -7.10526316,   3.94736842,   5.52631579,\n",
       "        -2.36842105,  13.42105263, -15.        ,  15.        ,\n",
       "        -5.52631579,   0.78947368, -11.84210526,  11.84210526,\n",
       "         2.36842105, -13.42105263,   8.68421053, -10.26315789])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaVec_sample = np.random.permutation(np.linspace(-15, 15, 20))\n",
    "#thetaVec_sample\n",
    "gg = [np.concatenate((np.array([theta_]), thetaVec_sample[1:])) for theta_ in np.nditer(thetaVec_sample)]\n",
    "gg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -18.37619967,  124.9886293 ,    0.69066491,   -2.38403005,\n",
       "         -2.3863598 ,   34.07749817,   -4.0086386 ,  -99.19477153,\n",
       "          5.28132817,  154.89424477,   17.32554579,  -64.2570698 ,\n",
       "         16.34582581,  -20.79296525,  -21.30831168,  -15.76185224,\n",
       "          4.64747081,  -65.70656672,   13.59414862,  -53.70279419,\n",
       "        113.13004224,  -33.56398667,    0.7257491 ,   -9.27982256,\n",
       "        -18.29977063,  129.48720956,  -37.57674034,  -30.04523486,\n",
       "        -90.35656788])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Closing Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.youtube.com/watch?v=e2sGq_vI41s (Elman Network Tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
